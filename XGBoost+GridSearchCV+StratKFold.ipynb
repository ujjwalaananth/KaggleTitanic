{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoost+GridSearchCV+StratKFold.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "v9ZkpsQQn2jR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction ##\n",
        "\n",
        "This notebook is written in python.\n",
        "The feature engineering is the work of Sina and the code below is inspired by [\"Titanic best working classifier\"][1].\n",
        "\n",
        "\n",
        "  [1]: https://www.kaggle.com/sinakhorami/titanic-best-working-classifier"
      ]
    },
    {
      "metadata": {
        "id": "6sEqZYC7stU7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "901bf8ed-b390-45b0-a386-c30f5fdd45e0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530798581765,
          "user_tz": -330,
          "elapsed": 9993,
          "user": {
            "displayName": "Ujjwala Ananth",
            "photoUrl": "//lh3.googleusercontent.com/-UC4tE75qOYI/AAAAAAAAAAI/AAAAAAAAB5Y/qncUR6JbhIU/s50-c-k-no/photo.jpg",
            "userId": "105670562238646173142"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5ab4b5da-a872-428c-ac9a-33e301e04de4\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-5ab4b5da-a872-428c-ac9a-33e301e04de4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.csv to test.csv\n",
            "Saving train.csv to train.csv\n",
            "User uploaded file \"test.csv\" with length 28629 bytes\n",
            "User uploaded file \"train.csv\" with length 61194 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XYlmpmrin2jV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "784b5269-ccb2-42e2-c18d-d08db8623146",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530798669181,
          "user_tz": -330,
          "elapsed": 839,
          "user": {
            "displayName": "Ujjwala Ananth",
            "photoUrl": "//lh3.googleusercontent.com/-UC4tE75qOYI/AAAAAAAAAAI/AAAAAAAAB5Y/qncUR6JbhIU/s50-c-k-no/photo.jpg",
            "userId": "105670562238646173142"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re as re\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
        "\n",
        "train1 = pd.read_csv('train.csv', header = 0, dtype={'Age': np.float64})\n",
        "test  = pd.read_csv('test.csv' , header = 0, dtype={'Age': np.float64})\n",
        "train=train1.drop(columns=['Survived'])\n",
        "allfeat = pd.concat([train, test],axis=0)\n",
        "print (train.info())\n",
        "print (train.shape)\n",
        "print (test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 11 columns):\n",
            "PassengerId    891 non-null int64\n",
            "Pclass         891 non-null int64\n",
            "Name           891 non-null object\n",
            "Sex            891 non-null object\n",
            "Age            714 non-null float64\n",
            "SibSp          891 non-null int64\n",
            "Parch          891 non-null int64\n",
            "Ticket         891 non-null object\n",
            "Fare           891 non-null float64\n",
            "Cabin          204 non-null object\n",
            "Embarked       889 non-null object\n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 76.6+ KB\n",
            "None\n",
            "(891, 11)\n",
            "(418, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LaKwENyLn2jf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering #"
      ]
    },
    {
      "metadata": {
        "id": "voz6D1Cvn2jg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Firstly, we drop all the features we won't be using here. Cabin has a lot of missing values. Hence, it will not be used. Also, Ticket and PassengerId are not relevant to our predictions."
      ]
    },
    {
      "metadata": {
        "id": "cB-2SjoUn2ji",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "allfeat=allfeat.drop(columns=['PassengerId','Cabin','Ticket'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kQOYnQOzn2jl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Pclass ##\n",
        "One hot encoding the values to represent different classes of the ship."
      ]
    },
    {
      "metadata": {
        "id": "U0a_ZAa3n2jm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "allfeat=pd.concat([allfeat,pd.get_dummies(allfeat['Pclass'])], axis=1) #getting one hot encoding for PClass and concatenating as new columns\n",
        "allfeat=allfeat.drop(columns=['Pclass']) #column no longer needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sh5fuDl1n2jp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Sex ##"
      ]
    },
    {
      "metadata": {
        "id": "oKxoLwbKn2jp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "allfeat=pd.concat([allfeat,pd.get_dummies(allfeat['Sex'])], axis=1) #getting one hot encoding for Sex and concatenating as new columns\n",
        "allfeat=allfeat.drop(columns=['Sex']) #column no longer needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bAur9zdjn2jt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. SibSp and Parch ##\n",
        "With the number of siblings/spouse and the number of children/parents we can create new feature called Family Size."
      ]
    },
    {
      "metadata": {
        "id": "6WShdropn2jt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "allfeat['FamilySize'] = allfeat['SibSp'] + allfeat['Parch'] + 1\n",
        "allfeat=allfeat.drop(columns=['SibSp','Parch']) #column no longer needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-aur-PFpn2jy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Another helpful feature would be to check whether they were travelling alone or not."
      ]
    },
    {
      "metadata": {
        "id": "tMk7QFGOn2jy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "allfeat['IsAlone'] = 0\n",
        "allfeat.loc[allfeat['FamilySize'] == 1, 'IsAlone'] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DPGo9-MKn2j1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Embarked ##\n",
        "The embarked feature has some missing values, so we try to fill those with the most frequent value ( 'S' )."
      ]
    },
    {
      "metadata": {
        "id": "w2U5Ja9kn2j3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "allfeat['Embarked'] = allfeat['Embarked'].fillna('S')\n",
        "allfeat=pd.concat([allfeat,pd.get_dummies(allfeat['Embarked'])],axis=1) #one-hot encoding the embarked categories\n",
        "allfeat=allfeat.drop(columns='Embarked') #column no longer needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "INY7T2jwn2j6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Fare ##\n",
        "Fare also has some missing values which we will replace with the median. Then we categorize it into 4 ranges, to reduce noise."
      ]
    },
    {
      "metadata": {
        "id": "eFzkwRDBn2j6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "allfeat['Fare'] = allfeat['Fare'].fillna(train['Fare'].median())\n",
        "allfeat['CategoricalFare'] = pd.qcut(allfeat['Fare'], 4)\n",
        "allfeat=pd.concat([allfeat,pd.get_dummies(allfeat['CategoricalFare'])],axis=1) #one-hot encoding the fare categories\n",
        "allfeat=allfeat.drop(columns=['Fare','CategoricalFare']) #column no longer needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PbX0XPwUn2j-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. Age ##\n",
        "We have plenty of missing values in this feature. # generate random numbers between (mean - std) and (mean + std).\n",
        "Again, to reduce noise, we categorize age into 5 range."
      ]
    },
    {
      "metadata": {
        "id": "IazvuqHbn2j_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "avg=allfeat['Age'].mean()\n",
        "std=allfeat['Age'].std()\n",
        "\n",
        "allfeat['Age']=allfeat['Age'].fillna(value=np.random.randint(avg-std,avg+std))\n",
        "allfeat['Age'] = allfeat['Age'].astype(int)\n",
        "    \n",
        "allfeat['CategoricalAge'] = pd.cut(allfeat['Age'], 5)\n",
        "allfeat=pd.concat([allfeat,pd.get_dummies(allfeat['CategoricalAge'])],axis=1) #one-hot encoding the age categories\n",
        "allfeat=allfeat.drop(columns=['Age','CategoricalAge']) #column no longer needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vEjKMeJzn2kA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 7. Name ##\n",
        "Here, we can find the titles of the passengers."
      ]
    },
    {
      "metadata": {
        "id": "oe1D1lU_n2kC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_title(name):\n",
        "\ttitle_search = re.search(' ([A-Za-z]+)\\.', name)\n",
        "\t# If the title exists, extract and return it.\n",
        "\tif title_search:\n",
        "\t\treturn title_search.group(1)\n",
        "\treturn \"\"\n",
        "\n",
        "allfeat['Title'] = allfeat['Name'].apply(get_title)\n",
        "allfeat=allfeat.drop(columns=['Name']) #column no longer needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vMyxmUphn2kF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have titles..."
      ]
    },
    {
      "metadata": {
        "id": "4KOSDygon2kH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "allfeat['Title'] = allfeat['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
        " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "\n",
        "allfeat['Title'] = allfeat['Title'].replace('Mlle', 'Miss')\n",
        "allfeat['Title'] = allfeat['Title'].replace('Ms', 'Miss')\n",
        "allfeat['Title'] = allfeat['Title'].replace('Mme', 'Mrs')\n",
        "    \n",
        "allfeat=pd.concat([allfeat,pd.get_dummies(allfeat['Title'])],axis=1) #one-hot encoding the Title categories\n",
        "allfeat=allfeat.drop(columns='Title') #column no longer needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WpeOR0BWn2kK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our dataset is almost ready. "
      ]
    },
    {
      "metadata": {
        "id": "rkK2WHvFn2kL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "5aabb919-e237-4260-f2d4-6bd6145d456f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530798681354,
          "user_tz": -330,
          "elapsed": 970,
          "user": {
            "displayName": "Ujjwala Ananth",
            "photoUrl": "//lh3.googleusercontent.com/-UC4tE75qOYI/AAAAAAAAAAI/AAAAAAAAB5Y/qncUR6JbhIU/s50-c-k-no/photo.jpg",
            "userId": "105670562238646173142"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print (list(allfeat))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 'female', 'male', 'FamilySize', 'IsAlone', 'C', 'Q', 'S', Interval(-0.001, 7.896, closed='right'), Interval(7.896, 14.454, closed='right'), Interval(14.454, 31.275, closed='right'), Interval(31.275, 512.329, closed='right'), Interval(-0.08, 16.0, closed='right'), Interval(16.0, 32.0, closed='right'), Interval(32.0, 48.0, closed='right'), Interval(48.0, 64.0, closed='right'), Interval(64.0, 80.0, closed='right'), 'Master', 'Miss', 'Mr', 'Mrs', 'Rare']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RNRt1MAsn2kO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "e9e19be5-fcc4-48a8-eb27-f7d6107d4341",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530798682841,
          "user_tz": -330,
          "elapsed": 1345,
          "user": {
            "displayName": "Ujjwala Ananth",
            "photoUrl": "//lh3.googleusercontent.com/-UC4tE75qOYI/AAAAAAAAAAI/AAAAAAAAB5Y/qncUR6JbhIU/s50-c-k-no/photo.jpg",
            "userId": "105670562238646173142"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#for xgboost classifier to work, we must rename the columns, removing the header names containing '()' and '[]'\n",
        "allfeat.columns=['1', '2', '3', 'female', 'male', 'FamSize', 'IsAlone', 'C', 'Q', 'S', 'fare1', 'fare2', 'fare3', 'fare4', \\\n",
        "                 'age1', 'age2', 'age3', 'age4', 'age5', 'Master', 'Miss', 'Mr', 'Mrs', 'Rare']\n",
        "print (list(allfeat))\n",
        "\n",
        "#now divide engineered dataset into train and test dataset\n",
        "X=allfeat[:][0:891]\n",
        "testdf=allfeat[:][891:1309]\n",
        "y=train1['Survived']"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1', '2', '3', 'female', 'male', 'FamSize', 'IsAlone', 'C', 'Q', 'S', 'fare1', 'fare2', 'fare3', 'fare4', 'age1', 'age2', 'age3', 'age4', 'age5', 'Master', 'Miss', 'Mr', 'Mrs', 'Rare']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AWYD7FSTn2kR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Applying Classifier using sklearn wrapper #\n",
        "Trial and error showed that min_child_weight had the most contribution to increasing accuracy of the classifier, with or without best values of the other parameters. We use Stratified K-Fold cross validation to obtain best model."
      ]
    },
    {
      "metadata": {
        "id": "eMvnMaEan2kS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "outputId": "f1e21ef2-0cfb-4832-e17a-9de476ab1cfe",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530799306051,
          "user_tz": -330,
          "elapsed": 622972,
          "user": {
            "displayName": "Ujjwala Ananth",
            "photoUrl": "//lh3.googleusercontent.com/-UC4tE75qOYI/AAAAAAAAAAI/AAAAAAAAB5Y/qncUR6JbhIU/s50-c-k-no/photo.jpg",
            "userId": "105670562238646173142"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "param_grid = [{'min_child_weight': np.arange(0.1, 10.1, 0.1)}] #set of trial values for min_child_weight\n",
        "i=1\n",
        "kf = StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\n",
        "for train_index,test_index in kf.split(X,y):\n",
        "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
        "     xtr,xvl = X.loc[train_index],X.loc[test_index]\n",
        "     ytr,yvl = y[train_index],y[test_index]\n",
        "     model = GridSearchCV(XGBClassifier(), param_grid, cv=10, scoring= 'f1',iid=True)\n",
        "     model.fit(xtr, ytr)\n",
        "     print (model.best_params_)\n",
        "     pred=model.predict(xvl)\n",
        "     print('accuracy_score',accuracy_score(yvl,pred))\n",
        "     i+=1\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1 of kfold 10\n",
            "{'min_child_weight': 1.3000000000000003}\n",
            "accuracy_score 0.8111111111111111\n",
            "\n",
            "2 of kfold 10\n",
            "{'min_child_weight': 6.4}\n",
            "accuracy_score 0.8444444444444444\n",
            "\n",
            "3 of kfold 10\n",
            "{'min_child_weight': 7.1}\n",
            "accuracy_score 0.8089887640449438\n",
            "\n",
            "4 of kfold 10\n",
            "{'min_child_weight': 4.9}\n",
            "accuracy_score 0.8426966292134831\n",
            "\n",
            "5 of kfold 10\n",
            "{'min_child_weight': 7.9}\n",
            "accuracy_score 0.7865168539325843\n",
            "\n",
            "6 of kfold 10\n",
            "{'min_child_weight': 1.6}\n",
            "accuracy_score 0.8764044943820225\n",
            "\n",
            "7 of kfold 10\n",
            "{'min_child_weight': 8.8}\n",
            "accuracy_score 0.8202247191011236\n",
            "\n",
            "8 of kfold 10\n",
            "{'min_child_weight': 7.0}\n",
            "accuracy_score 0.8089887640449438\n",
            "\n",
            "9 of kfold 10\n",
            "{'min_child_weight': 1.0}\n",
            "accuracy_score 0.8202247191011236\n",
            "\n",
            "10 of kfold 10\n",
            "{'min_child_weight': 8.1}\n",
            "accuracy_score 0.8295454545454546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cbYrUAInn2kW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prediction #\n",
        "We can use the same classifier we just trained. Finally, store the predicted array in a pandas DataFrame, and save in .csv file for submission."
      ]
    },
    {
      "metadata": {
        "id": "3JjhE4n9n2kW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "op=pd.DataFrame(data={'PassengerId':test['PassengerId'],'Survived':model.predict(testdf)})\n",
        "op.to_csv('KFold_XGB_GridSearchCV_submission.csv',index=False)\n",
        "files.download('KFold_XGB_GridSearchCV_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}